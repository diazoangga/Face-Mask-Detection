{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_for_frames(video_path):\n",
    "    print(video_path)\n",
    "    frames = glob(os.path.join(video_path, '*.jpg'))\n",
    "    frames.sort()\n",
    "\n",
    "    flow = []\n",
    "    prev = cv2.imread(frames[0])\n",
    "    prev = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "    prev = cv2.resize(prev,(224,224))\n",
    "    for i, frame_curr in enumerate(frames):\n",
    "        curr = cv2.imread(frame_curr)\n",
    "        curr = cv2.resize(curr,(224,224))\n",
    "        curr = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "        tmp_flow = compute_TVL1(prev, curr)\n",
    "        flow.append(tmp_flow)\n",
    "        prev = curr\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_TVL1(prev, curr, bound=15):\n",
    "    \"\"\"Compute the TV-L1 optical flow.\"\"\"\n",
    "    TVL1 = cv2.optflow.DualTVL1OpticalFlow_create()\n",
    "    flow = TVL1.calc(prev, curr, None)\n",
    "    flow = np.clip(flow, -20,20) #default values are +20 and -20\n",
    "    #print(flow)\n",
    "    assert flow.dtype == np.float32\n",
    "\n",
    "    flow = (flow + bound) * (255.0 / (2*bound))\n",
    "    flow = np.round(flow).astype(int)\n",
    "    flow[flow >= 255] = 255\n",
    "    flow[flow <= 0] = 0\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flow(video_flows, flow_path):\n",
    "    #The optical flows are generated in 3D. However for I3D only first two channels are used. u is the first channel \n",
    "    #and v is the second channel. Both u and v are saved in separate folders in the flow_path directory. \n",
    "    #The u and v folders will be generated by calling create_path() function\n",
    "    n_py=[]\n",
    "    for i, flow in enumerate(video_flows):\n",
    "        cv2.imwrite(os.path.join(flow_path.format('u'), \"{:06d}.jpg\".format(i)),\n",
    "                    flow[:, :, 0])\n",
    "        cv2.imwrite(os.path.join(flow_path.format('v'), \"{:06d}.jpg\".format(i)),\n",
    "                    flow[:, :, 1])\n",
    "        n_py.append(np.dstack([flow[:, :, 0],flow[:, :, 1]]))\n",
    "    return n_py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flow(args):\n",
    "    video_path, flow_path = args\n",
    "    flow = cal_for_frames(video_path)\n",
    "    save_flow(flow, flow_path)\n",
    "    print('complete:' + flow_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paths(base_path,activity):\n",
    "    activity_path=os.path.join(base_path,activity)\n",
    "    rgb_folder=os.makedirs('{}/{}_rgb'.format(activity_path,activity))\n",
    "    flow_folder1=os.makedirs('{}/{}_flow/u'.format(activity_path,activity))\n",
    "    flow_folder2=os.makedirs('{}/{}_flow/v'.format(activity_path,activity))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vid_to_image(base_path,file,frame_path):\n",
    "    folder=file.split('.')[0]\n",
    "    #print(folder)\n",
    "    #os.mkdir(os.path.join(base_path,folder))\n",
    "    vidcap = cv2.VideoCapture(file)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    frame_no=0\n",
    "    print(frame_path)\n",
    "    while success:\n",
    "            vidcap.set(1,frame_no)\n",
    "            #print(os.path.join(frame_path,\"frame%d.jpg\"))\n",
    "            cv2.imwrite(os.path.join(frame_path,\"frame%d.jpg\") % count, image)     # save frame as JPEG file     \n",
    "            success,image = vidcap.read()\n",
    "            #print('Read a new frame: ', success)\n",
    "            count += 1\n",
    "            frame_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of activity what is in the video. This is just for purpose of creating proper folders.\n",
    "\n",
    "activity='cricket'\n",
    "\n",
    "#This is the path where your video is kept. for simplicity rename the video same as activity. for eg. laughing.mp4\n",
    "base_path='/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function creates folders u and v which store the optical flow images\n",
    "create_paths(base_path,activity)\n",
    "\n",
    "#This is the path where  images sampled from the video are to be saved\n",
    "frame_path='/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/train/{}/{}_rgb/'.format(activity,activity) \n",
    "\n",
    "# this is the path where you want save the flow files.\n",
    "flow_path='/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/train/{}/{}_flow/{}'.format(activity,activity,{}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/train/cricket/cricket_rgb/\n"
     ]
    }
   ],
   "source": [
    "#Convert your video to frames and save in to activity_rgb folder\n",
    "vid_to_image(base_path,os.path.join(base_path,activity+'.mp4'),frame_path)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "flow_path.format('u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lenovo/object-detection/spot-on/I3D/kinetics-i3d/convert_vid2npy/train/cricket_samp/cricket_samp_rgb/\n"
     ]
    }
   ],
   "source": [
    "#calculate flows\n",
    "flow = cal_for_frames(frame_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save flows to folders u and v\n",
    "npy_flow=save_flow(flow, flow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to .npyfile as descibed in  https://github.com/deepmind/kinetics-i3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "# print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create npy file for rgb files as described in deepmind I3D\n",
    "def norm_rgb(rgb_path,nchannel):\n",
    "    #print(video_path)\n",
    "    npy_file=[]\n",
    "    frames = glob(os.path.join(rgb_path, '*.jpg'))\n",
    "    frames.sort()\n",
    "    print(len(frames))\n",
    "    for frame in frames:\n",
    "        img=cv2.imread(os.path.join(frame_path,frame))\n",
    "        img_new=(cv2.resize(img,(224,224))).astype(float)\n",
    "        img_norm=np.divide(2*(img_new-img_new.min()),(img_new.max()-img_new.min()))-1\n",
    "        \n",
    "        npy_file.append(img_norm)\n",
    "        \n",
    "    npy_file=np.reshape(np.asarray(npy_file),(1,len(frames),224,224,nchannel))\n",
    "    np.save('data_input_rgb_{}.npy'.format(activity),npy_file)\n",
    "    return npy_file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create npy file of flow files as described in deepmind I3D\n",
    "def norm_flow(rgb_path,nchannel):\n",
    "    #print(video_path)\n",
    "#     npy_file=[]\n",
    "    frames = glob(os.path.join(rgb_path, '*.jpg'))\n",
    "    frames.sort()\n",
    "    print(len(frames))\n",
    "#     for frame in frames:\n",
    "#         img=cv2.imread(os.path.join(frame_path,frame),0)\n",
    "#         #img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         img_new=(cv2.resize(img,(224,224))).astype(float)\n",
    "#         img_norm=np.divide(2*(img_new-img_new.min()),(img_new.max()-img_new.min()))-1\n",
    "        \n",
    "#         npy_file.append(img_norm[:,:,:-1])\n",
    "        \n",
    "    npy_file=np.reshape(np.asarray(npy_flow),(1,len(frames),224,224,nchannel-1)).astype(float)\n",
    "    #clip between range [0,40]\n",
    "    #npy_file=np.clip(npy_file,-20,20)\n",
    "    #rescale betwwen [-1,1]\n",
    "    npy_file=((2*(npy_file-npy_file.min())/(npy_file.max()-npy_file.min()))-1)\n",
    "    np.save('data_input_flow_{}.npy'.format(activity),npy_file)\n",
    "    return npy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "np_file=norm_rgb(frame_path,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "np_file=norm_flow(frame_path,3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "npy_file=np.reshape(np.asarray(npy_flow),(1,70,224,224,2)).astype(float)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "((2*(npy_file-npy_file.min())/(npy_file.max()-npy_file.min()))-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.clip(npy_file,0,40).max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "myarr=np.dstack([np.array([[10,9,6],[32,45,67],[909,456,786]]),np.array([[13,45,0],[67,89,12],[132,476,756]])])\n",
    "myarr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xx=np.reshape(np.asarray(npy_flow),(1,70,224,224,2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(xx[0][2][:,:,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
